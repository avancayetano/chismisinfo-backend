"""
This type stub file was generated by pyright.
"""

import abc
import dataclasses
import functools
import requests
import requests.adapters
import urllib3.connection

__all__ = [
    "DeprecatedFeatureWarning",
    "IntWithGranularity",
    "Item",
    "Scraper",
    "ScraperException",
]
_logger = ...

class DeprecatedFeatureWarning(FutureWarning): ...

class _DeprecatedProperty:
    def __init__(self, name, repl, replStr) -> None: ...
    def __get__(self, obj, objType): ...

@dataclasses.dataclass
class _JSONDataclass:
    """A base class for dataclasses for conversion to JSON"""

    def json(self):  # -> str:
        """Convert the object to a JSON string"""
        ...

@dataclasses.dataclass
class Item(_JSONDataclass):
    """An abstract base class for an item returned by the scraper.

    An item can really be anything. The string representation should be useful for the CLI output (e.g. a direct URL for the item).
    """

    @abc.abstractmethod
    def __str__(self) -> str: ...

class IntWithGranularity(int):
    """A number with an associated granularity

    For example, an IntWithGranularity(42000, 1000) represents a number on the order of 42000 with two significant digits, i.e. something counted with a granularity of 1000.
    """

    def __new__(cls, value, granularity, *args, **kwargs): ...
    def __reduce__(self): ...

class _HTTPSAdapter(requests.adapters.HTTPAdapter):
    def init_poolmanager(self, *args, **kwargs): ...

class _HTTPSConnection(urllib3.connection.HTTPSConnection):
    def connect(self, *args, **kwargs): ...

class ScraperException(Exception): ...

class Scraper:
    """An abstract base class for a scraper."""

    name = ...
    def __init__(self, *, retries=..., proxies=...) -> None: ...
    @abc.abstractmethod
    def get_items(self):  # -> None:
        """Iterator yielding Items."""
        ...
    @functools.cached_property
    def entity(self): ...

def nonempty_string(name): ...
